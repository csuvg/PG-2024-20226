{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729701702.676223 35830851 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1729701702.687876 35830851 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx.mirror_x import mirror_x\n",
    "from Modules import utils\n",
    "\n",
    "videosTrain = \"Videos/Train/Normal\"\n",
    "flippedVideosTrain = \"Videos/Train/Flipped\"\n",
    "\n",
    "videosTest = \"Videos/Test/Normal\"\n",
    "flippedVideosTest = \"Videos/Test/Flipped\"\n",
    "\n",
    "mpHands = mp.solutions.hands.Hands()\n",
    "mpFace = mp.solutions.face_mesh.FaceMesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729701702.693373 35834928 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1729701702.696359 35834928 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1729701702.696369 35834917 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729701702.707714 35834917 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "100%|██████████| 385/385 [00:00<00:00, 43195.14it/s]\n",
      "100%|██████████| 97/97 [00:00<00:00, 47045.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def flipVideo(videoFile, videoPath, newVideoPath):\n",
    "    videoPath = os.path.join(videoPath, videoFile)\n",
    "    newVideoPath = os.path.join(newVideoPath, videoFile)\n",
    "\n",
    "    if not os.path.exists(newVideoPath) and videoFile.endswith(\".mp4\"):\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "        video = VideoFileClip(videoPath)\n",
    "        flippedVideo = video.fx(mirror_x)\n",
    "        flippedVideo.write_videofile(newVideoPath, codec=\"libx264\")\n",
    "\n",
    "        sys.stdout = sys.__stdout__\n",
    "                \n",
    "for videoFile in tqdm.tqdm(os.listdir(videosTrain)):\n",
    "    flipVideo(videoFile, videosTrain, flippedVideosTrain)\n",
    "\n",
    "for videoFile in tqdm.tqdm(os.listdir(videosTest)):\n",
    "    flipVideo(videoFile, videosTest, flippedVideosTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoData = []\n",
    "rawVideoData = []\n",
    "frameSkip = 5\n",
    "\n",
    "def processVideo(videoFile, videoPath):\n",
    "    if not videoFile.endswith(\".mp4\"):\n",
    "        return None, None\n",
    "    \n",
    "    thisVideo = {\"SENTENCE\": \"\", \"COORDINATES\": []}\n",
    "    allVideoData = {\"FILE\": \"\", \"HANDS\": [], \"FACE\": []}\n",
    "\n",
    "    sentence = videoFile.split('-')[0]\n",
    "\n",
    "    videoPath = os.path.join(videoPath, videoFile)\n",
    "    \n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    \n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    currentFrame = 0 \n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        currentFrame += 1\n",
    "        if currentFrame <= frameSkip or currentFrame > frameCount - frameSkip:\n",
    "            continue\n",
    "        \n",
    "        coordinates = utils.processFrame(frame, mpHands, mpFace)\n",
    "        hands, face = utils.getDataFromFrame(frame, mpHands, mpFace)\n",
    "\n",
    "        allVideoData[\"HANDS\"].append(hands)\n",
    "        allVideoData[\"FACE\"].append(face)\n",
    "        \n",
    "        thisVideo[\"COORDINATES\"].append(coordinates)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    thisVideo[\"SENTENCE\"] = sentence\n",
    "    allVideoData[\"FILE\"] = videoFile\n",
    "    return thisVideo, allVideoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/385 [00:00<?, ?it/s]W0000 00:00:1729701702.828220 35834912 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "100%|██████████| 385/385 [39:45<00:00,  6.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for videoFile in tqdm.tqdm(os.listdir(videosTrain)):\n",
    "    thisVideo, allVideoData = processVideo(videoFile, videosTrain)\n",
    "\n",
    "    if thisVideo is None:\n",
    "        continue\n",
    "    else:\n",
    "        videoData.append(thisVideo)\n",
    "        rawVideoData.append(allVideoData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [39:30<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for videoFile in tqdm.tqdm(os.listdir(flippedVideosTrain)):\n",
    "    thisVideo, allVideoData = processVideo(videoFile, flippedVideosTrain)\n",
    "\n",
    "    if thisVideo is None:\n",
    "        continue\n",
    "    else:\n",
    "        thisVideo[\"SENTENCE\"] = thisVideo[\"SENTENCE\"] + \"_INV_\"\n",
    "        videoData.append(thisVideo)\n",
    "        rawVideoData.append(allVideoData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes:  (64,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(videoData)\n",
    "unprocessedDF = pd.DataFrame(rawVideoData)\n",
    "\n",
    "df[\"SENTENCE\"] = df[\"SENTENCE\"].str.replace(\"Baño\", \"Baño\")\n",
    "unprocessedDF[\"FILE\"] = unprocessedDF[\"FILE\"].str.replace(\"Baño\", \"Baño\")\n",
    "\n",
    "print(\"Unique classes: \", df[\"SENTENCE\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'Data/LENSEGUA.pkl'\n",
      "Shape of the data: (768, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>COORDINATES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tu</td>\n",
       "      <td>[[-23, 379, 4, 354, 33, 333, 64, 328, 87, 330,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoy</td>\n",
       "      <td>[[], [-127, 566, -98, 535, -54, 526, -16, 536,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que</td>\n",
       "      <td>[[], [270, 714, 242, 726, 232, 751, 227, 776, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universidad</td>\n",
       "      <td>[[], [-93, 484, -51, 483, -17, 503, 2, 525, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como</td>\n",
       "      <td>[[], [-117, 655, -84, 668, -65, 693, -52, 713,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SENTENCE                                        COORDINATES\n",
       "0           Tu  [[-23, 379, 4, 354, 33, 333, 64, 328, 87, 330,...\n",
       "1          Hoy  [[], [-127, 566, -98, 535, -54, 526, -16, 536,...\n",
       "2          Que  [[], [270, 714, 242, 726, 232, 751, 227, 776, ...\n",
       "3  Universidad  [[], [-93, 484, -51, 483, -17, 503, 2, 525, 12...\n",
       "4         Como  [[], [-117, 655, -84, 668, -65, 693, -52, 713,..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('Data/LENSEGUA.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "df.to_excel('Data/LENSEGUA.xlsx')\n",
    "\n",
    "print(\"Data saved to 'Data/LENSEGUA.pkl'\")\n",
    "print(\"Shape of the data:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed data saved to 'Data/LENSEGUA_RAW.pkl'\n",
      "Shape of the unprocessed data: (768, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>HANDS</th>\n",
       "      <th>FACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tu-Der-3.mp4</td>\n",
       "      <td>[[landmark {\\n  x: 0.487129629\\n  y: 0.5540930...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoy-Frente-4.mp4</td>\n",
       "      <td>[[landmark {\\n  x: 0.461057961\\n  y: 0.5892689...</td>\n",
       "      <td>[[landmark {\\n  x: 0.528064\\n  y: 0.180241063\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que-Izq-3.mp4</td>\n",
       "      <td>[[landmark {\\n  x: 0.663456559\\n  y: 0.7785301...</td>\n",
       "      <td>[[landmark {\\n  x: 0.533213139\\n  y: 0.2177261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universidad-Der-3.mp4</td>\n",
       "      <td>[[landmark {\\n  x: 0.515573382\\n  y: 0.6067475...</td>\n",
       "      <td>[[landmark {\\n  x: 0.551567614\\n  y: 0.2571026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como-Izq-3.mp4</td>\n",
       "      <td>[[landmark {\\n  x: 0.491495907\\n  y: 0.7319240...</td>\n",
       "      <td>[[landmark {\\n  x: 0.539612174\\n  y: 0.1967032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    FILE                                              HANDS  \\\n",
       "0           Tu-Der-3.mp4  [[landmark {\\n  x: 0.487129629\\n  y: 0.5540930...   \n",
       "1       Hoy-Frente-4.mp4  [[landmark {\\n  x: 0.461057961\\n  y: 0.5892689...   \n",
       "2          Que-Izq-3.mp4  [[landmark {\\n  x: 0.663456559\\n  y: 0.7785301...   \n",
       "3  Universidad-Der-3.mp4  [[landmark {\\n  x: 0.515573382\\n  y: 0.6067475...   \n",
       "4         Como-Izq-3.mp4  [[landmark {\\n  x: 0.491495907\\n  y: 0.7319240...   \n",
       "\n",
       "                                                FACE  \n",
       "0  [None, None, None, None, None, None, None, Non...  \n",
       "1  [[landmark {\\n  x: 0.528064\\n  y: 0.180241063\\...  \n",
       "2  [[landmark {\\n  x: 0.533213139\\n  y: 0.2177261...  \n",
       "3  [[landmark {\\n  x: 0.551567614\\n  y: 0.2571026...  \n",
       "4  [[landmark {\\n  x: 0.539612174\\n  y: 0.1967032...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('Data/LENSEGUA_RAW.pkl', 'wb') as f:\n",
    "    pickle.dump(unprocessedDF, f)\n",
    "\n",
    "unprocessedDF.to_excel('Data/LENSEGUA_RAW.xlsx')\n",
    "print(\"Unprocessed data saved to 'Data/LENSEGUA_RAW.pkl'\")\n",
    "print(\"Shape of the unprocessed data:\", unprocessedDF.shape)\n",
    "unprocessedDF.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
